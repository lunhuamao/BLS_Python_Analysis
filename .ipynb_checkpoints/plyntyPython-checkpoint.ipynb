{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plynty Bureau of Labor Statistics Consumer Expenditure Analysis\n",
    "\n",
    "[BLS Comsumer Expenditure Survey](https://www.bls.gov/cex/home.htm)\n",
    "\n",
    "[Interview Data Dictionary](https://www.bls.gov/cex/2015/csxintvwdata.pdf)\n",
    "\n",
    "[Diary Data Dictionary](https://www.bls.gov/cex/2015/csxdiarydata.pdf)\n",
    "\n",
    "### Where to download the BLS CE PUMD\n",
    "- The zip files download automatically\n",
    "- To download the Stub files open the links then right click and choose \"Save As...\"\n",
    "\n",
    "[2015 interview zip file](https://www.bls.gov/cex/pumd/data/comma/intrvw15.zip)\n",
    "\n",
    "[2015 diary zip file](https://www.bls.gov/cex/pumd/data/comma/diary15.zip)\n",
    "\n",
    "[2015 IntStub file](https://www.bls.gov/cex/pumd/2014/csxintstub.txt)\n",
    "\n",
    "[2015 IStub file](https://www.bls.gov/cex/pumd/2014/csxistub.txt)\n",
    "\n",
    "[2015 DStub file](https://www.bls.gov/cex/pumd/2014/csxdstub.txt)\n",
    "\n",
    "### This Scripts Goals for Plynty\n",
    "- Create an easy to use analysis engine for the BLS CE PUMD \n",
    "- Create a csv files that has average percentages spent on plynty categories for certain income classes\n",
    "- Create incomeclasses that are stastically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mywidgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Parameters\n",
    "- year: the last two number associated with the year of the data\n",
    "    for example for data from 2015: year = \"15\"\n",
    "- minAge: the low bound (inclusive) of the age range you wish to subset by\n",
    "- maxAge: the high bound (inclusive) of the age range you wish to subset by\n",
    "- incomeBrackets: array of numbers that you wish to create the new income classes\n",
    "    the bracketing works as follows (1,2], (2,3], (3,4]\n",
    "- filesToRead: the strings of the abbreviations associated with the files you wish to read\n",
    "    options are: \"all\", \"diary\", \"interview\", \"dtbd\", \"expd\", \"fmld\", \"memd\", \"fmli\", \"itbi\", \"memi\", \"mtbi\", \"ntaxi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year = \"15\"\n",
    "# hard coding ages\n",
    "# minAge = 55\n",
    "# maxAge = 64\n",
    "# filesToRead = [\"fmli\", \"mtbi\"]\n",
    "incomeBrackets = [-math.inf,11000,20000,30000,43000,55000,69000,80000,100000,120000,150000,200000,250000,300000,math.inf]\n",
    "\n",
    "# Cool widgets\n",
    "display(ageRange, readFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the widgets to set values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The age range is: 55-64\n",
      "The files being read in are:\n",
      "fmli\n",
      "mtbi\n"
     ]
    }
   ],
   "source": [
    "# setting age range using the cool widget\n",
    "minAge = ageRange.value[0]\n",
    "maxAge = ageRange.value[1]\n",
    "print(\"The age range is: \"+str(minAge)+\"-\"+str(maxAge))\n",
    "filesToRead = readFiles.value\n",
    "print(\"The files being read in are:\")\n",
    "print(*filesToRead, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Directory locations and FileNames on your Local Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory in which the diary and interview folders are held is located\n",
    "diaryDir = \"/Users/adyke/Vizuri/CE_PUMD/diary15/\"\n",
    "interviewDir = \"/Users/adyke/Vizuri/CE_PUMD/intrvw15/\"\n",
    "\n",
    "# Directory where stubfiles are located\n",
    "pathToStubFileDir = \"/Users/adyke/Vizuri/Stubfiles/\"\n",
    "rScriptStubfilePathAndName = \"/Users/adyke/Vizuri/rFiles/creatingStubCsvs.R\"\n",
    "\n",
    "# Filenames of the Stubfiles\n",
    "IStubFileName = \"IStub2015.txt\"\n",
    "DStubFileName = \"DStub2015.txt\"\n",
    "IntStubFileName = \"IntStub2015.txt\"\n",
    "\n",
    "# name of interview dir within the interview dir\n",
    "insideIntrvwDirName = \"intrvw\"\n",
    "\n",
    "# name of the directory where you want the output percentages csv\n",
    "outputDir = \"/Users/adyke/Vizuri/outputFiles/\"\n",
    "\n",
    "print(ageRange.value[0])\n",
    "print(minAge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read File Set Function\n",
    "Function that was built to easily read in and concatinate multiple files that start with the same abbreviation.\n",
    "\n",
    "#### Parameters:\n",
    "- fileabbreviation: The four letters associated with the files you wish to read in (ex. \"fmli\")\n",
    "- directory: path to the directory that holds files that should be read in.\n",
    "\n",
    "#### Returns:\n",
    "- pandas dataframe of all the files that start with the fileabbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFileSet(fileabbreviation, directory):\n",
    "\t# finding all the files with names that start with the fileabbreviation\n",
    "\tfilenames = glob.glob(directory+fileabbreviation+\"*.csv\")\n",
    "\tdfs = []\n",
    "\tfor filename in filenames:\n",
    "\t\tdfs.append(pd.read_csv(filename, na_values=[\".\"]))\n",
    "\tlargeDataframe = pd.concat(dfs,ignore_index=True)\n",
    "\treturn largeDataframe\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the files specified by FilesToRead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if(len(filesToRead)>0):\n",
    "\tprint(\"Reading in files...\")\n",
    "else:\n",
    "\tprint(\"The files to read variable is empty.\")\n",
    "\n",
    "# looping through each file to read\n",
    "for file in filesToRead:\n",
    "\tif file == \"dtbd\" or file == \"all\" or file == \"diary\":\n",
    "\t\tprint(\"dtbd\")\n",
    "\t\tdtbd = readFileSet(\"dtbd\", diaryDir)\n",
    "\tif file == \"expd\" or file == \"all\" or file == \"diary\":\n",
    "\t\tprint(\"expd\")\n",
    "\t\texpd = readFileSet(\"expd\", diaryDir)\n",
    "\tif file == \"fmld\" or file == \"all\" or file == \"diary\":\n",
    "\t\tprint(\"fmld\")\n",
    "\t\tfmld = readFileSet(\"fmld\", diaryDir)\n",
    "\tif file == \"memd\" or file == \"all\" or file == \"diary\":\n",
    "\t\tprint(\"memd\")\n",
    "\t\tmemd = readFileSet(\"memd\", diaryDir)\n",
    "\tif file == \"fmli\" or file == \"all\" or file == \"interview\":\n",
    "\t\tprint(\"fmli\")\n",
    "\t\tfmli = readFileSet(\"fmli\", interviewDir+insideIntrvwDirName+year+\"/\")\n",
    "\tif file == \"itbi\" or file == \"all\" or file == \"interview\":\n",
    "\t\tprint(\"itbi\")\n",
    "\t\titbi = readFileSet(\"itbi\", interviewDir+insideIntrvwDirName+year+\"/\")\n",
    "\tif file == \"itii\" or file == \"all\" or file == \"interview\":\n",
    "\t\tprint(\"itii\")\n",
    "\t\titii = readFileSet(\"itii\", interviewDir+insideIntrvwDirName+year+\"/\")\n",
    "\tif file == \"memi\" or file == \"all\" or file == \"interview\":\n",
    "\t\tprint(\"memi\")\n",
    "\t\tmemi = readFileSet(\"memi\", interviewDir+insideIntrvwDirName+year+\"/\")\n",
    "\tif file == \"mtbi\" or file == \"all\" or file == \"interview\":\n",
    "\t\tprint(\"mtbi\")\n",
    "\t\tmtbi = readFileSet(\"mtbi\", interviewDir+insideIntrvwDirName+year+\"/\")\n",
    "\tif file == \"ntaxi\" or file == \"all\" or file == \"interview\":\n",
    "\t\tprint(\"ntaxi\")\n",
    "\t\tntaxi = readFileSet(\"ntaxi\", interviewDir+insideIntrvwDirName+year+\"/\")\n",
    "\t# does not read form the expn or para subdirectories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using R to convert the Stub files into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converting the stub files via R \n",
    "subprocess.call(\"Rscript \"+rScriptStubfilePathAndName+\" \"+pathToStubFileDir+\" \"+IStubFileName+\" \"+DStubFileName+\" \"+IntStubFileName, shell=True)\n",
    "print(\"Stubfile Csvs created in \"+pathToStubFileDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Cleaning the stubfile CSVs into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading in the stubfiles\n",
    "DStub = pd.read_csv(pathToStubFileDir+\"DStub.csv\")\n",
    "IStub = pd.read_csv(pathToStubFileDir+\"IStub.csv\")\n",
    "IntStub = pd.read_csv(pathToStubFileDir+\"IntStub.csv\")\n",
    "\n",
    "# removing the index from the stufile\n",
    "DStub = DStub.drop(DStub.columns[0], axis=1)\n",
    "IStub = IStub.drop(IStub.columns[0], axis=1)\n",
    "IntStub = IntStub.drop(IntStub.columns[0], axis=1)\n",
    "\n",
    "# replacing * with 0 in the level columns\n",
    "DStub.loc[DStub.level == \"*\", 'level'] = 0\n",
    "IStub.loc[IStub.level == \"*\", 'level'] = 0\n",
    "IntStub.loc[IntStub.level == \"*\", 'level'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subsetDataframe function\n",
    "Used to subset any dataframe based on certain parameters\n",
    "#### Parameters:\n",
    "- dataframe: the pandas dataframe to subset\n",
    "- columnName: \n",
    "- minValue: this has 3 different uses\n",
    "  1. the single value you wish to subset by\n",
    "  2. the array of values that you wish to subset by\n",
    "  3. the minimum value (inclusive) in a range of values you wish to subset by\n",
    "- secondColumnName: the name of the second column if you wish to subest the dataframe\n",
    "- maxValue: the highest value in a range of values you wish to subset by\n",
    "\n",
    "#### Returns:\n",
    "\n",
    "- subset pandas dataframe\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subsetDataframe(dataframe, columnName,  minValue, secondColumnName = None, maxValue = None):\n",
    "\tif columnName in dataframe.columns:\n",
    "\t\t# only subsetting based off one column\n",
    "\t\tif secondColumnName == None:\n",
    "\t\t\t# subsetting not within a range\n",
    "\t\t\tif maxValue == None:\n",
    "\t\t\t\tvalue = minValue\n",
    "\t\t\t\t# value is a list\n",
    "\t\t\t\tif isinstance(value, list):\n",
    "\t\t\t\t\tdataframe = dataframe[dataframe[columnName].isin(value)]\n",
    "\t\t\t\t# value is scalar\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdataframe = dataframe[dataframe[columnName]==value]\n",
    "\t\t\t# the subsetting is within a range\n",
    "\t\t\telse:\n",
    "\t\t\t\tdataframe = dataframe[(dataframe[columnName]>=minValue) & (dataframe[columnName]<=maxValue)]\n",
    "\t\t# subsetting based on two columns\n",
    "\t\telse:\n",
    "\t\t\t# subsetting not within a range\n",
    "\t\t\tif maxValue == None:\n",
    "\t\t\t\tvalue = minValue\n",
    "\t\t\t\t# value is a list\n",
    "\t\t\t\tif isinstance(value, list):\n",
    "\t\t\t\t\tdataframe = dataframe[(dataframe[columnName].isin(value)) & (dataframe[secondColumnName].isin(value))]\n",
    "\t\t\t\t# value is scalar\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdataframe = dataframe[(dataframe[columnName]==value) & (dataframe[secondColumnName]==value)]\n",
    "\t\t\t# the subsetting is within a range\n",
    "\t\t\telse:\n",
    "\t\t\t\tdataframe = dataframe[((dataframe[columnName]>=minValue) & (dataframe[columnName]<=maxValue)) & ((dataframe[secondColumnName]>=minValue) & (dataframe[secondColumnName]<=maxValue)) ]\n",
    "\t\treturn(dataframe)\n",
    "\telse:\n",
    "\t\tprint(\"Could not a column named \"+columnName+\" in the dataframe\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binColumn function\n",
    "This function is used in the plynty analysis to recode the income classes to specified incomeclasses\n",
    "#### Parameters:\n",
    "- dataframe: the pandas dataframe that you wish to bin a column of\n",
    "- toBinColumnName: name of column you wish use use as values to bin\n",
    "- binValues: array of values that are the ranges of the bins\n",
    "- binLabels: labels assocaiated with the bins you wish to create\n",
    "- binnedColumnName: name of the column that you wish to replace or create\n",
    "\n",
    "#### Returns:\n",
    "- dataframe with the binned column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def binColumn(dataframe, toBinColumnName, binValues, binnedColumnName, labels=None):\n",
    "    if labels==None:\n",
    "        dataframe[binnedColumnName] = pd.cut(dataframe.loc[:,toBinColumnName], bins=binValues)\n",
    "    else:\n",
    "        dataframe[binnedColumnName] = pd.cut(dataframe.loc[:,toBinColumnName], bins=binValues, labels=labels)\n",
    "    return(dataframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RepresentInts function\n",
    "function that determines if a string can be repesented as an integer\n",
    "\n",
    "Created by stackoverflow user [Triptych](https://stackoverflow.com/users/43089/triptych) and posted in [this](https://stackoverflow.com/questions/1265665/python-check-if-a-string-represents-an-int-without-using-try-except) stackoverflow question\n",
    "\n",
    "#### Parameters:\n",
    "- s: the string that you wish to check\n",
    "\n",
    "#### Returns:\n",
    "- boolean: retruns true if the string can be represented as an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RepresentsInt(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical UCC Roll Up function\n",
    "\n",
    "#### Parameters:\n",
    "- stubfile: the stubfile you are using to create the roll up\n",
    "- abbreviations: an array of strings taht contain the abbreviations that you wish to roll up \n",
    "- ignoreUCCs: an array that you wish to not add into your roll up\n",
    "\n",
    "#### Returns:\n",
    "- an array of the uccs associated with your abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categoricalUCCRollUp(stubfile,abbreviations,ignoreUCCs=None):\n",
    "\tuccs = []\n",
    "\tfor abbreviation in abbreviations:\n",
    "\t\tstartingRows = stubfile[stubfile['ucc']==abbreviation].index.tolist()\n",
    "\t\tfor startingRow in startingRows:\n",
    "\t\t\tstartingLevel = stubfile.at[startingRow,'level']\n",
    "\t\t\tcurrentRow = startingRow+1\n",
    "\t\t\tcurrentLevel = stubfile.at[currentRow,'level']\n",
    "\t\t\twhile int(startingLevel) < int(currentLevel):\n",
    "\t\t\t\tif RepresentsInt(stubfile.at[currentRow,'ucc']):\n",
    "\t\t\t\t\tif ignoreUCCs==None:\n",
    "\t\t\t\t\t\tuccs.append(stubfile.at[currentRow,'ucc'])\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif not(stubfile.at[currentRow,'ucc'] in ignoreUCCs):\n",
    "\t\t\t\t\t\t\tuccs.append(stubfile.at[currentRow,'ucc'])\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\tcurrentRow += 1\n",
    "\t\t\t\tcurrentLevel = stubfile.at[currentRow,'level']\n",
    "\treturn(uccs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the UCC roll ups for Plynty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating UCC rollups for the interview files for plynty categories\n",
    "iTotalExp = categoricalUCCRollUp(IStub,[\"TOTALE\"])\n",
    "iFoodAtHome = categoricalUCCRollUp(IStub, [\"FOODHO\", \"ALCHOM\"])\n",
    "iFoodAway = categoricalUCCRollUp(IStub, [\"FOODAW\", \"ALCAWA\"])\n",
    "iHousing = categoricalUCCRollUp(IStub, [\"HOUSIN\"], ignoreUCCs = categoricalUCCRollUp(IStub, [\"UTILS\"]))\n",
    "iUtilites = categoricalUCCRollUp(IStub, [\"UTILS\"])\n",
    "iClothingAndBeauty = categoricalUCCRollUp(IStub, [\"APPARE\",\"PERSCA\"])\n",
    "iTransportation = categoricalUCCRollUp(IStub, [\"TRANS\"])\n",
    "iHealthcare = categoricalUCCRollUp(IStub, [\"HEALTH\"])\n",
    "iEntertainment = categoricalUCCRollUp(IStub, [\"ENTRTA\",\"READIN\"])\n",
    "iMiscellaneous = categoricalUCCRollUp(IStub, [\"MISC\",\"TOBACC\"])\n",
    "iCharitableAndFamilyGiving = categoricalUCCRollUp(IStub, [\"CASHCO\"])\n",
    "iInsurance = categoricalUCCRollUp(IStub, [\"LIFEIN\"])\n",
    "iEducation = categoricalUCCRollUp(IStub, [\"EDUCAT\"])\n",
    "iHousingPrinciple = categoricalUCCRollUp(IStub,[\"MRTPRI\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and reseting the indecies of the MTBI file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# restting the index\n",
    "mtbi.reset_index()\n",
    "\n",
    "# Change mtbi UCC column to string\n",
    "# needed for the loop through rollups\n",
    "mtbi.UCC = mtbi.UCC.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding and Rolling up the Categories into the mtbi Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rollupNames = [\"iTotalExp\",\"iFoodAtHome\",\"iFoodAway\",\"iHousing\",\"iUtilites\",\"iClothingAndBeauty\",\"iTransportation\",\"iHealthcare\",\"iEntertainment\",\"iMiscellaneous\",\"iCharitableAndFamilyGiving\",\"iInsurance\",\"iEducation\",\"iHousingPrinciple\"]\n",
    "rollups = [iTotalExp,iFoodAtHome,iFoodAway,iHousing,iUtilites,iClothingAndBeauty,iTransportation,iHealthcare,iEntertainment,iMiscellaneous,iCharitableAndFamilyGiving,iInsurance,iEducation,iHousingPrinciple]\n",
    "\n",
    "mtbiRolledUp = mtbi\n",
    "\n",
    "# looping through the different rollup columns\n",
    "for x in range(len(rollupNames)):\n",
    "\tquarters = 4\n",
    "\tif(rollupNames[x] == \"iHousingPrinciple\"):\n",
    "\t\tquarters = -4\n",
    "\tmtbiRolledUp[rollupNames[x]] = np.where(mtbiRolledUp['UCC'].isin(rollups[x]), mtbiRolledUp['COST']*4, 0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimming the mtbi dataframe to be the columns we care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# renaming the dataframe to make partial runs easy\n",
    "mtbiTrimmed = mtbiRolledUp\n",
    "\n",
    "mtbiTrimmed = mtbiTrimmed.loc[: , ['NEWID','iTotalExp','iFoodAtHome','iFoodAway','iHousing','iUtilites','iClothingAndBeauty','iTransportation','iHealthcare','iEntertainment','iMiscellaneous','iCharitableAndFamilyGiving','iInsurance','iEducation','iHousingPrinciple']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Sum for all expenditure category columns for each NEWID\n",
    "Testing removing the rows that have 0 response for columns that we think are important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adding up all columns for each new id\n",
    "iExpensesByNewID = mtbiTrimmed.groupby(['NEWID'],as_index=False).sum()\n",
    "# removing rows with zero values in key categories\n",
    "nonZeroColumns = ['iFoodAtHome','iFoodAway','iHousing','iUtilites']\n",
    "for column in nonZeroColumns:\n",
    "    iExpensesByNewID = iExpensesByNewID[iExpensesByNewID[column] != 0]\n",
    "# iExpensesByNewID['iHousing'] = iExpensesByNewID['iHousing']-iExpensesByNewID['iHousingPrinciple']\n",
    "\n",
    "iExpensesByNewID.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subestting FMLI for age and recoding the incomebrackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# subsetting for the age bracket\n",
    "fmliAge = subsetDataframe(dataframe=fmli, columnName=\"AGE_REF\", minValue=minAge, maxValue=maxAge)\n",
    "fmliAge = fmliAge.reset_index()\n",
    "\n",
    "# recoding the income brackets\n",
    "fmliRecoded = binColumn(dataframe=fmliAge, toBinColumnName=\"FINCBTXM\", binValues=incomeBrackets, binnedColumnName=\"INCLASS\", labels=range(1,len(incomeBrackets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the Income class colum to the ExpensesByNewID dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combining the fmli and iExpensesByNewID\n",
    "inclassExpenses = pd.merge(left=fmliRecoded[['NEWID','INCLASS']],right=iExpensesByNewID, on=['NEWID'])\n",
    "# inclassExpenses.head(10)\n",
    "# nonZeroColumns = ['iFoodAtHome','iFoodAway','iHousing','iUtilites']\n",
    "# for column in nonZeroColumns:\n",
    "#     inclassExpenses = inclassExpenses[inclassExpenses[column] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Averaging the expenditures based on incomebrackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# getting mean for all columns with the same income class besides newId and creating new dataframe\n",
    "inclassAverages = round(inclassExpenses.ix[: ,inclassExpenses.columns != 'NEWID'].groupby(['INCLASS'],as_index=False).mean(),2)\n",
    "# doing median instead of average\n",
    "# inclassAverages = round(inclassExpenses.ix[: ,inclassExpenses.columns != 'NEWID'].groupby(['INCLASS'],as_index=False).median(),2)\n",
    "\n",
    "inclassAverages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median of the expenditures based on income brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inclassMedians = round(inclassExpenses.ix[:,inclassExpenses.columns != 'NEWID'].groupby(['INCLASS'],as_index=False).median(),2)\n",
    "inclassMedians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the Average expenditures for income classes into percentages of expenditures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating new dataframe for the percentages that only includes the plynty categories\n",
    "percentages = inclassAverages.loc[:,rollupNames[1:]]\n",
    "for column in rollupNames[1:]:\n",
    "    percentages[column] = inclassAverages[column]/inclassAverages.iTotalExp\n",
    "    \n",
    "percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the Median expenditures for income classes into percentages of expenditures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating new dataframe for the percentages that only includes the plynty categories\n",
    "percentagesM = inclassMedians.loc[:,rollupNames[1:]]\n",
    "for row in range(len(percentagesM)):\n",
    "    # creating the row total for \"row\"\n",
    "    rowTotal = percentagesM.loc[row,percentagesM.columns != 'iTotalExp'].sum()\n",
    "    # replacing each element with the percent\n",
    "    for column in rollupNames[1:]:\n",
    "        percentagesM.loc[row,column] = percentagesM.loc[row,column]/rowTotal\n",
    "    \n",
    "# dataframe that contains the percentages for medians\n",
    "percentagesM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Csv of percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# percentages.to_csv(outputDir+\"plyntyCsv.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph of number of observations in the income brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ploting the number of people in each bracket\n",
    "print(fmliRecoded['INCLASS'].value_counts().values)\n",
    "print(fmliRecoded['INCLASS'].value_counts().values.sum())\n",
    "plt.bar(list(fmliRecoded['INCLASS'].value_counts().index.tolist()), fmliRecoded['INCLASS'].value_counts().values, align='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Standard Deviations\n",
    "\n",
    "What I'm finding is that the higher income brackets (>150k) have high standard deviations for housing\n",
    "this might have to do with the non reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inclassSD = inclassExpenses.groupby(['INCLASS'],as_index=False).std()\n",
    "inclassSD.iloc[:,~inclassSD.columns.isin(['INCLASS','NEWID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking negative values for housing for incomeclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for inclass in range(len(incomeBrackets)-1):\n",
    "    print(len(inclassExpenses.loc[inclassExpenses.iHousing <= 0].loc[inclassExpenses.INCLASS == inclass]))\n",
    "inclassExpenses.loc[inclassExpenses.iHousing <= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking deeper into housing and why its janky\n",
    "- What im finding is that the negative values in the housing column stay consistent while the max values go up\n",
    "- Negative values come from the housing principle\n",
    "- The large negatives could happen when the iHousing reporting is 0 and they report the housing principle\n",
    "- for some reason there is an issue with the 0 incomeclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# max and min of housing per income class\n",
    "for inclass in range(1,len(incomeBrackets)-1):\n",
    "    print(inclass)\n",
    "    print(inclassExpenses.iHousing.loc[inclassExpenses.INCLASS == inclass].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look into the stub files to see if there are changed abbreviations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "203b9144330447b2b32f87f49248834a": {
     "views": [
      {
       "cell_index": 4
      },
      {
       "cell_index": 4
      }
     ]
    },
    "74d2284d26eb433798815947f1807de3": {
     "views": [
      {
       "cell_index": 4
      },
      {
       "cell_index": 4
      }
     ]
    },
    "bcb69d23bc884c97a50c5dd2d42ee7a9": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "db01390f926543ae84a6112a711293b2": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
